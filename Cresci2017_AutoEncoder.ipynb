{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPBK+evWa+ZiKPQKFUnLbo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DFwJZ/Real-time_Bot_Detection/blob/main/Cresci2017_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "img2TwbLzxuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uzhLjclzOWf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, LeakyReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "kY1Gnqavzc1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Input, Lambda, LeakyReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import mse, binary_crossentropy\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class VAE:\n",
        "    \"\"\"\n",
        "    VAE represents a Deep Variational Autoencoder architecture with mirrored encoder and decoder components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_shape, intermediate_dim, latent_space_dim):\n",
        "        self.input_shape = input_shape  # (768,)\n",
        "        self.intermediate_dim = intermediate_dim  # e.g., 256\n",
        "        self.latent_space_dim = latent_space_dim  # e.g., 10\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.model = None\n",
        "\n",
        "        self.mu = None  # Mean\n",
        "        self.log_variance = None  # Variance\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        self._build_encoder()\n",
        "        self._build_decoder()\n",
        "        self._build_autoencoder()\n",
        "\n",
        "    def _build_encoder(self):\n",
        "        encoder_input = Input(shape=self.input_shape, name=\"encoder_input\")\n",
        "        x = Dense(self.intermediate_dim, activation='relu')(encoder_input)\n",
        "\n",
        "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
        "        self.log_variance = Dense(self.latent_space_dim, name=\"log_variance\")(x)\n",
        "\n",
        "        def sample_point_from_normal_distribution(args):\n",
        "            mu, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
        "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
        "            return sampled_point\n",
        "\n",
        "        encoder_output = Lambda(sample_point_from_normal_distribution, name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "\n",
        "        self.encoder = Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "\n",
        "    def _build_decoder(self):\n",
        "        decoder_input = Input(shape=(self.latent_space_dim,), name=\"decoder_input\")\n",
        "        x = Dense(self.intermediate_dim, activation='relu')(decoder_input)\n",
        "        decoder_output = Dense(np.prod(self.input_shape), activation='sigmoid')(x)\n",
        "\n",
        "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        autoencoder_input = Input(shape=self.input_shape, name=\"autoencoder_input\")\n",
        "        encoded_img = self.encoder(autoencoder_input)\n",
        "        decoded_img = self.decoder(encoded_img)\n",
        "        self.model = Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
        "\n",
        "    def compile(self, learning_rate=0.0001):\n",
        "        self.model.compile(optimizer=Adam(learning_rate), loss=self._calculate_combined_loss,\n",
        "                           metrics=[self._calculate_reconstruction_loss, self._calculate_kl_loss])\n",
        "\n",
        "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
        "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
        "        combined_loss = reconstruction_loss + kl_loss\n",
        "        return combined_loss\n",
        "\n",
        "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = mse(y_target, y_predicted)\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
        "        kl_loss = 1 + self.log_variance - K.square(self.mu) - K.exp(self.log_variance)\n",
        "        kl_loss = K.sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        return kl_loss\n",
        "\n",
        "    def train(self, x_train, batch_size, num_epochs):\n",
        "        self.model.fit(x_train, x_train, batch_size=batch_size, epochs=num_epochs, shuffle=True)\n",
        "\n",
        "    def summary(self):\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()"
      ],
      "metadata": {
        "id": "wEfqqhtbzxCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    autoencoder = VAE(\n",
        "        input_shape = 768,\n",
        "        intermediate_dim = 256,  # e.g., 256\n",
        "        latent_space_dim = 10  # e.g., 10\n",
        "    )\n",
        "    autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ssSvb-4uE6",
        "outputId": "86810bfe-2f23-4a9b-e9c9-df60a10f57c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          196864      ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " mu (Dense)                     (None, 10)           2570        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " log_variance (Dense)           (None, 10)           2570        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " encoder_output (Lambda)        (None, 10)           0           ['mu[0][0]',                     \n",
            "                                                                  'log_variance[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 202,004\n",
            "Trainable params: 202,004\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 10)]              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               2816      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 768)               197376    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200,192\n",
            "Trainable params: 200,192\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " autoencoder_input (InputLay  [(None, 768)]            0         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " encoder (Functional)        (None, 10)                202004    \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 768)               200192    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 402,196\n",
            "Trainable params: 402,196\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}